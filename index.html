<!DOCTYPE html>
<html lang="en">

 <head>
        <title>Joseph DeFrank</title>
        <link href="style.css" rel="stylesheet">
        <meta name="author" content="Joseph DeFrank">
 </head>
    
    <body>
            <header>
                <h1>Joseph DeFrank</h1>
                    <nav>
                        <ul>
                            <li><a href="#home">Home</a></li>
                            <li><a href="#text">Intro to Text Analysis</a></li>
                            <li><a href="#cv">Curriculum Vitae </a></li>
                        </ul>
                    </nav>
            </header>

            <section>
                <h2>Home <p id="home"> </h2>
                <p>Hello there! I am a historian of religion with a focus on identity. </p>
        
                <p>This website is primarily designed to showcase my digital humanities skills. </p> 
                
                <p>Below is a simple text analysis exercise and my CV!</p>
                   
              </section>

        
              <section>
                <h2>Intro to Text Analysis <p id="text"></p></h2>
                <h3>No Experience, No Problem: A Digital History Introduction for Educators </h3>
                
                <p>Words like “digital history” seem mysterious. Digital history implies computers, coding, and something arcane about history. Perhaps lines of code from The Matrix, cyberpunk clad individuals, and virtual reality simulations come to mind. Digital history is mundane, but people inside and outside of the academy use it every day. As more archives appear online, apps preserve local history, and researchers use digital methods, digital history is becoming a necessary skill for everyone. Hence, it is important that students learn how to use digital history tools, specifically text analysis tools, to better prepare them for their futures. If you are an educator who has little or no previous experience in digital history, this article is for you! I will begin by explaining some basic concepts about digital history, how to acquire text documents that you can analyze with your students, and three different text analysis programs to be a digital historian. Therefore, defining “digital history” is an important first step. </p> 

                <p>Digital history is an amorphous label. It tends to be used in two different meanings. One is the use of computers to display information about something that scholars want publics to pay attention to.1 These projects take a variety of forms, such as videos, podcasts, maps, interactive animations, and games. In another sense, digital history means projects that use software to analyze materials. While the “digital” part can mean many things, for our purposes we will think of digital humanities as having three components. These three components are: the machine is interpreting something, organizing it, and presenting it.2 What is the input, what is the output, and how is it usable by a human? It really is that simple. </p> 
                    
                <p>A basic word processor, such as notepad or WordPad, will be functioning as our input. Most computers already have a basic word processor or similar programs installed. This is because they use text document files. While Microsoft Word or a similar program might work, basic word processors are preferred because they are open access. On the other hand, Microsoft releases a new version of Word annually and saves documents as doc or docx file. This requires the machine, or any human, to have Microsoft Word or be able to interpret. Ergo, text document files are the way to go. There are many places text document files can be acquired. There are many groups dedicated to volunteer-sourced text-transcribing.3 One example is the Gutenberg project. An open access philanthropy since 1971, this group provides out of copyright books for free download. For our purposes, we will need the plain text version of the book. Another place to find plain text documents is your local historical society or museum. These groups generally have their own archives that are probably digitized. So this project can easily be constructed to add a local history component to the project!  </p>   
              
                <p>These plain text files provide a great opportunity to engage with students about the mechanisms of making history. Why should we choose some documents over others? By being associated with a university, museum, or historic society, it might make the source material more legitimate. Especially if the source material includes a scan of the original document. These originals are usually PDFs. One last thing to note about where the sources come from is which material included in the transcript version was not part of the original source. For example, most Project Gutenberg books include context material at the beginning and end of the document. Additionally, simple text documents cannot have pictures, so concise illustration descriptions are usually bracketed in the document. This provides a fruitful opportunity to engage with students about source material. Should this publication information, illustration descriptions, and footnotes be removed before running our analysis? The answer might seem obvious, but it is worth pausing to consider. Altering the primary texts may seem like an insignificant action in a case like this. But why does it seem so obviously correct to remove them? Sure, the Project Guttenberg information was added later than the original writings. However, we should be attentive to the intention of why we alter our documents, even in a simple project like this one.  </p>

                <p>For this project, I gathered several books from the Project Guttenberg website. All seven of these books originate from the late nineteenth or early twentieth century. Each book is titled, “A Brief history of the United States,” or some variation of it. My aim in doing so was to see what word associations the text analysis tools would make for histories that claimed to study the entire United States. As stated earlier, these are plain text documents which claim to encompass the then-totality of United States history. Now that my plain text files have been gathered, the question becomes, “should I change them?”. For this experiment, I deleted the initial publication information and any transcription notes at the end of the book. I did not remove the illustration information. First, although the bracketed text describing the illustration does not perfectly describe the image, it does provide a summation. Seeing what words the text analysis tools decide to link with illustration does indeed say something about the materials. Second, this was a choice of practicality. While I intentionally avoided books that claimed to be an illustrated history of America, there were simply too many illustrations for me to realistically remove them all. Recognizing the practical limitations of an experiment, in digital history or any other discipline, is a useful skill. It should be part of the learning process. For example, Cameron Blevins realized that including advertisements in their analysis of Houston newspapers, while initially a limiting factor of the analysis, added depth to the study.4A practical limitation can lead to new insights. In the case of this project, it provides an excellent opportunity for students to practice being forthright with the decisions they make in their research.   </p>
                
                <p>Now that we have our plain text documents assembled, we need to choose which software will analyze the text. These text analysis tools are a form of what is called “distant reading” by data scientists and historians. Distant reading’s goal is for researchers to analyze documents without reading the documents themselves. In a world with so many documents, it is unrealistic for any one person to be able to read them all. While there are many text analysis software tools out there, many of them do some form of topic analysis. Imagine you want to arrange every word in a book into different topics. Depending on which topics you choose to assign words into, words might be grouped together in surprising ways. If the topic is “food,” do you also include cutlery and cooking? In this way, the text analysis software takes the words in a corpus –a corpus being all of the examined texts—and assigns them into a specified number of topics.</p>
            
                <p>For this experiment, I experimented with three different text software analysis tools. One of the easiest to operate is Voyant. This program requires no downloading or installation to run. Simply open it in your web browser and begin examining. “Unlike early models, which, in the most liberal sense, are representations of scholarly interpretations, current experiments in visualization are representations for scholarly interpretation.”5 Voyant demonstrates how words are linked. A user can interface with the illustrations to spatially see how terms are related. Additionally, a user can manually search for a term that they want to know more about, such as how many times it appears in the sample group. Voyant can even calculate such things as the correlation and significance of two terms. To put it frankly, Voyant is a very user-friendly tool.</p>
            
                <p>To demonstrate this, I inputted my own documents into Voyant. You can even play around with the resulting analysis here!6 For example, in my sample group (or corpus), I was surprised to see the word “new” appear a total of 3499 times as the overwhelmingly common term. Voyant demonstrated that the terms with the most significant correlation are “states,” “war,” “great,” “French,” and “fort.” These correlations did not surprise me except for “French.” Given how US history is often focused on settler colonialism expansion and warfare, I was bemused that “French” was such a common term. After examining the “TermsBerry” graphic, it became apparent that “new” frequently appeared with “England” and “York.” Therefore, my theory is that “French” appears so often with new because of emphasis on French involvement in 18th century events in New England and New York. After “new,” the nine most used terms were “states” (3030), “war” (2622), “great” (1988), “general (1747), “president” (1733), “men” (1718), “united” (1693), “state” (1680), and “American” (1650). Just because these terms appear frequently does mean there is an equal distribution across all of the books. Voyant can then populate these terms into multiple charts.7 For example, while “men” is used frequently in the documents, it appears the most in the Pierson and Blamire History of the United States in Words of One Syllable. This makes sense, given the limitations of such a text. </p>

                <p>Another useful text analysis tool is the appropriately named “TopicModelingTool.” Unlike Voyant, this tool does require to be downloaded before it is ran. However, the program has a simple installation process. Simply download the zipped folder onto your computer, unzip it, open the folder, and double click on the item titled “TopicModelingTool.exe” to get it running. All that is needed is java. The easy installation process makes it foreseeably appropriate for students of virtually all technological skills. Such an easy installation correlates with it being such a simple tool. Unlike Voyant, TopicModelingTool has a single purpose: it scans the files in a folder, assigns the terms in that folder to a topic, and then deposits the results into an output folder. The results will come out in two groups, one in csv files (which can be opened in excel documents) and one in html (which can be opened by an internet browser). Remember; just because it is opened in a web browser does not mean it is on the internet. If you copy and send someone the words where the website link usually is, you will be sending them a copy of the html file location on your device.6 They will not be able to see your work.</p>

                <p>So far, it might seem like I have described TopicModelingTool as a less valuable tool than Voyant. A better way to think of it is that TopicModelingTool is very effective at the one thing it is designed to do. After several iterations, I found that the TopicModelingTool could organize the text in my documents in close to two hundred different topics. One of the interesting topic structures that stood out to me was, “army general union Washington years battle early day Grant present colony long surrender admitted return close back body advance age.” By clicking on the topic to expand it, TopicModelingTool presents the top ranked documents in this topic. So for the “army general union” topic, it mainly seems to be in Steele’s A Brief History of the United States and Adams and Trents’ A History of the United States. Almost 7% and 4% of the words in these books respectively were assigned to this topic. That may not sound like a lot, but when there are 159 other topics, that is a significant portion of the words to be assigned.  </p>

                <p>One more text analysis software I want to touch on is Mallet. This is a program used by many scholars and researchers in the academy. Due to the lengthy setup process, I would not suggest this text analysis software for young students or large classes. I will not go through all the steps of the installation process, but it is difficult. I found this video to be helpful with working through the steps.7 This digital historian article was also useful.8 However, I was unable to successfully get Mallett to operate on my computer. Although I successfully downloaded and opened Mallett in my computer’s command prompt, I am unable to make it work with my computer’s JavaScript. This is a shame because theory behind it, known as latent Dirichlet Allocation, is incredible.9 But just like when programs are successful, talking about why programs do not work is a learning opportunity. Failure is acceptable. Learning new strategies to solve digital problems is paramount to being a good learner of digital history.</p>

                <p>Where you choose to acquire your texts, which software you wish to use, and which elements of the process you want to focus on will ultimately be up to you; just know that many of these programs are user friendly. Whether or not we think of ourselves as digital historians, we often perform similar tasks to the software performs on these documents. Creating learning opportunities with students with these programs, even if the experiment goes wrong, provides useful conversations about history meaning and making. Where does subject material come from? Why are we using this method or software instead of another? What are the important topics? Perhaps these questions and the other ones inspired by these projects do not make us better humans, but they do make us better thinkers. Rather than thinking of history as rote memorization, digital history provides a way for us as scholars to think of history in a more self-reflexive way. </p>
                        
                    <h3>Endnotes</h3>
                        <ol>
                            <li><a href="https://rrchnm.org/argument-white-paper/" >Arguing with Digital History working group, “Digital History and Argument,” white paper, Roy Rosenzweig Center for History and New Media (November 13, 2017): 1-9.</a></li>
                            <li>Ibid, 13-15.</li>
                            <li><a href="https://edsitement.neh.gov/teachers-guides/digital-humanities-and-online-education"> "Digital Humanities and Online Education,” National Endowment for the Humanities, https://edsitement.neh.gov/teachers-guides/digital-humanities-and-online-education. </a></li>
                            <li><a href="http://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93" >Cameron Blevins, “Mining and Mapping the Production of Space: A View of the World from Houston,” Stanford University Spatial History Project, http://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93</a></li>
                            <li>Amy E. Earhart, “Data and the Fragmented Text: Tools, Visualization, and Datamining or IsBigger Better?” in Traces of the Old, Uses of the New: The Emergence of Digital Literary Studies (Ann Arbor: University of Michigan Press, 2015), 101.</li>
                            <li>For example, here is the file location for my project where the website link usually would be: file:///C:/Users/defra/Documents/Alabama/Academic%20Courses/Spring%202021/HY%20500/Final%20Project/output_html/all_topics.html.</li>
                            <li><a href="https://www.youtube.com/watch?v=zVzUotS9GpQ"> Angel San, “Mallet Quick Start Tutorial,” YouTube,April 16, 2017, https://www.youtube.com/watch?v=zVzUotS9GpQ</a></li>
                            <li><a href="https://programminghistorian.org/en/lessons/topic-modeling-and-mallet#windows-instructions" > Shawn,Graham, and Scott Weingart, and Ian Milligan,“Getting Started with Topic Modeling and MALLET,” The Programming Historian,published September 2, 2012; last modified February 26, 2021,https://programminghistorian.org/en/lessons/topic-modeling-and-mallet#windows-instructions. </a></li>
                            <li> David M. Blei, “Introduction to Probabilistic Topic Models,”inCommunications of the ACM55, no. 4, (2012): 77-80.</li>
                           
                <h3> Works Cited </h3>
                            
                        </ol>
                        <ul>
                            <li> <a href= "https://rrchnm.org/argument-white-paper/" >Arguing with Digital History working group, “Digital History and Argument,” white paper, Roy Rosenzweig Center for History and New Media(November 13, 2017): 1-29. https://rrchnm.org/argument-white-paper/ </a></li>
                            <li> Blei, David M. “Introduction to Probabilistic Topic Models.”Communications of the ACM55, no. 4. (2012): 77-84.</li>
                            <li> <a href= "http://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93" >Blevins, Cameron.“Mining and Mapping the Production of Space: A View of the World from Houston.” Stanford University Spatial History Project. http://web.stanford.edu/group/spatialhistory/cgi-bin/site/pub.php?id=93 </a></li>
                            <li> <a href= "https://edsitement.neh.gov/teachers-guides/digital-humanities-and-online-education" >“Digital Humanities and Online Education.” National Endowment for the Humanities. https://edsitement.neh.gov/teachers-guides/digital-humanities-and-online-education </a></li>
                            <li> <a href= "https://programminghistorian.org/en/lessons/topic-modeling-and-mallet#windows-instructions" >Graham,Shawn,and Scott Weingart, and Ian Milligan. “Getting Started with Topic Modeling and MALLET.” The Programming Historian. Published September 2, 2012; Last Modified February 26, 2021. https://programminghistorian.org/en/lessons/topic-modeling-and-mallet#windows-instructions </a></li>
                            <li> Earhart, AmyE. "Data and the Fragmented Text: Tools, Visualization, and Datamining or Is Bigger Better?" In Traces of the Old, Uses of the New: The Emergence of Digital Literary Studies, 90-116. Ann Arbor: University of Michigan Press, 2015. </li>
                            <li> <a href= "https://www.youtube.com/watch?v=zVzUotS9GpQ" >San, Angel. “Mallet Quick Start Tutorial.” YouTube. April 16, 2017. https://www.youtube.com/watch?v=zVzUotS9GpQ </a></li>
                        </ul>

                 <a href= "#top"> Take me back to the top! </a> 
            </section>

              <section>
                <h2>Curriculum Vitae <p id="cv"></p></h2>
                <p>Coming soon!</p>
                   
                <a href= "#top"> Take me back to the top! </a> 
              </section>
              
    </body>

</html>
